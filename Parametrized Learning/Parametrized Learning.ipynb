{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parametrized Learning\n",
    "While k-NN and other methods without learning may be enough for some simple applications, it becomes unusable when we require a huge amount of info, because always that we need to make the image classification all the database needs to be available and that's not the case with parametrized Learning\n",
    "Parametrized Learning lays on the learning of some parameters that represent the set of data, and just these parameters will be used on future classifications. \n",
    "So, simply put, after the model is trained, all we need are the values of the parameters to classsify our datapoint, and not the whole dataset. \n",
    "\n",
    "### Four Components of Parametrized Learning\n",
    "In machine learning, the parametrization uses four parameters that will be defined below:\n",
    "\n",
    " - #### Data\n",
    "Data consists of our dataset with the respective labels\n",
    "> In a 1000 images dataset, with 32x32 pixels RGB each, the data would be a matrix with dimensions [1000x32x32x3]\n",
    "\n",
    " - #### Weights and Biases\n",
    "The weights are the parameters of the classifier, or how each pixel will pass through each of the nodes of the network.\n",
    "> If there are three possible classes for classification, the weight's matrix size is [3x3072] and the bias matrix size [1x3072]\n",
    "\n",
    " - #### Scoring Function \n",
    "The scoring function is what makes your predictions, simple put, it reads your input data, make some kind of transform to it, multiply with the weights and outputs the predicted labels.\n",
    "> An example of scoring funtion is in the linear classification, the function is WeightsMatrix*Inputs+BiasMatrix\n",
    "\n",
    " - #### Loss Function\n",
    "The loss function is a measure of how well your algorithm is behaving. This function is used to tune up the weights and so make a better model.\n",
    "> An example of Loss Function is the Hinge Loss Function, that is sum(max(0, sj-syi+1)), that means: take the max between the scoring value of the right class minus the scoring value of the each of the classes.\n",
    "> If the loss fucntion for a image is 0, it means it have correctly guessed the datapoint, because the right class has the biggest value, so all  the subtractions results are negative and the max takes the 0\n",
    "\n",
    "### Starting the action\n",
    "So now, we'll show what are the parameters through an example.\n",
    "\n",
    "The dataset in this case will be just one 32x32 RGB pixels image. So data will be a [32x32x3] matrix, that will be flatten in a 3072 array.\n",
    "\n",
    "The weights matrix and the bias matrix will be randomly choosen (that's not something that we'll do in the following projects) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Initialize class labels and set the seed of our pseudo-random number generator\n",
    "# '1' is chosen as the seed because it gives the 'correct classification'\n",
    "labels = ['dog', 'cat', 'panda']\n",
    "np.random.seed(1)\n",
    "\n",
    "# Randomly initialize the weight and bias vectors between 0 and 1\n",
    "w = np.random.randn(3, 3072)\n",
    "b = np.random.randn(3)\n",
    "\n",
    "# Load image, resize it (ignoring the aspect ratio) and flatten it\n",
    "original = cv2.imread('beagle.png')\n",
    "image = cv2.resize(original, (32, 32)).flatten()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scores will of the linear classification type, so we'll use the form WeightsMatrix*Inputs+BiasMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: dog: 7963.93\n",
      "[INFO]: cat: -2930.99\n",
      "[INFO]: panda: 3362.47\n"
     ]
    }
   ],
   "source": [
    "# Compute the output scores\n",
    "scores = w.dot(image) + b\n",
    "\n",
    "# Loop over the scores and labels to display them\n",
    "for label, score in zip(labels, scores):\n",
    "    print('[INFO]: {}: {:.2f}'.format(label, score))\n",
    "\n",
    "# Draw the label with the highest score on the image as our prediction\n",
    "cv2.putText(original, 'Label: {}'.format(labels[np.argmax(scores)]), (10, 30),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "# Display our input image\n",
    "cv2.imshow(\"Image\", original)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
