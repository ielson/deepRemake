{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameterized Learning\n",
    "While k-NN and other methods without learning may be enough for some simple applications, it becomes unusable when we require a huge amount of info, because always that we need to make the image classification all the database needs to be available and that's not the case with Parameterized Learning\n",
    "Parameterized Learning lays on the learning of some parameters that represent the set of data, and just these parameters will be used on future classifications. \n",
    "So, simply put, after the model is trained, all we need are the values of the parameters to classsify our datapoint (image), and not the whole dataset. \n",
    "\n",
    "### Four Components of Parametrized Learning\n",
    "In machine learning, the parametrization uses four parameters that will be defined below:\n",
    "\n",
    " - #### Data\n",
    "Data consists of our dataset with the respective labels\n",
    "> In a 1000 images dataset, with 32x32 pixels RGB each, the data would be a matrix with dimensions [1000x32x32x3]\n",
    "\n",
    " - #### Weights and Biases\n",
    "The weights are the parameters of the classifier, or how each pixel will pass through each of the nodes of the network.\n",
    "> If there are three possible classes for classification (K), the weight's matrix size is [3x3072] (Kx3072) and the bias matrix size [3x1] (Kx1). Meaning the output, i.e the classification is some function that maps the weights and biases to a class label.  \n",
    "\n",
    " - #### Scoring Function \n",
    "The scoring function is what makes your predictions, simple put, it reads your input data, make some kind of transform to it, multiply with the weights and outputs the predicted labels.\n",
    "> An example of scoring function is in the linear classification, which is defined as WeightsMatrix*Inputs+BiasMatrix\n",
    "The output in this case would be 3x1 given the dot product between two matrices and then the sum [3x3072]*[3072x1]+[3x1] = [3x1]. Which means we would get an array of three possible values with the respective scores of each class (the higher the score the higher the probability is of the classified image (Input) belonging to the class).\n",
    "\n",
    "\n",
    " - #### Loss Function\n",
    "The loss function is a measure of how well your algorithm is behaving. This function is used to tune up the weights and so make a better model. When the weights and bias are correctly tuned we switch then from the Training set to the Test set and see the real proof that our model is predicting correctly.\n",
    "> As mentioned before the Scoring Function returns (in our case) three values [3x1], meaning we would get certain values for each class label. The right class is represented as [sj] and [syi] is the other two classes.\n",
    "> An example of Loss Function is the Hinge Loss Function, that is L = sum(max(0, sj-syi+1)), that means: take the max between the scoring value of the right class minus the scoring value of the each of the classes.\n",
    "> If the loss function for a image is 0 (L=0), it means it have correctly guessed the datapoint (image), because the right class has the biggest value, so all the subtractions results are negative and the max yields the 0.\n",
    "\n",
    "### Starting the action\n",
    "So now, we'll show what are the parameters through an example.\n",
    "\n",
    "The dataset in this case will be just one 32x32 RGB pixels image. So data will be a [32x32x3] matrix, that will be flatten in a 3072 array.\n",
    "\n",
    "The weights matrix and the bias matrix will be randomly choosen (that's not something that we'll do in the following projects) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Initialize class labels and set the seed of our pseudo-random number generator\n",
    "# '1' is chosen as the seed because it gives the 'correct classification'\n",
    "labels = ['dog', 'cat', 'panda']\n",
    "np.random.seed(1)\n",
    "\n",
    "# Randomly initialize the weight and bias vectors between 0 and 1\n",
    "w = np.random.randn(3, 3072)\n",
    "b = np.random.randn(3)\n",
    "\n",
    "# Load image, resize it (ignoring the aspect ratio) and flatten it\n",
    "original = cv2.imread('beagle.png')\n",
    "image = cv2.resize(original, (32, 32)).flatten()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scores will of the linear classification type, so we'll use the form WeightsMatrix*Inputs+BiasMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: dog: 7963.93\n",
      "[INFO]: cat: -2930.99\n",
      "[INFO]: panda: 3362.47\n"
     ]
    }
   ],
   "source": [
    "# Compute the output scores\n",
    "scores = w.dot(image) + b\n",
    "\n",
    "# Loop over the scores and labels to display them\n",
    "for label, score in zip(labels, scores):\n",
    "    print('[INFO]: {}: {:.2f}'.format(label, score))\n",
    "\n",
    "# Draw the label with the highest score on the image as our prediction\n",
    "cv2.putText(original, 'Label: {}'.format(labels[np.argmax(scores)]), (10, 30),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "# Display our input image\n",
    "cv2.imshow(\"Image\", original)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
